{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves to load and test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "\n",
    "import kaggle\n",
    "kaggle.api.dataset_download_files('ankanghosh651/object-detection-wildlife-dataset-yolo-format', path='./content/data', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.20 ðŸš€ Python-3.11.8 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Setup complete âœ… (16 CPUs, 7.6 GB RAM, 132.6/1006.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Import comet for metric logging\n",
    "\n",
    "import comet_ml\n",
    "comet_ml.init()\n",
    "\n",
    "# Import ultralytics\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = './runs/detect/train_X/weights/best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(PATH_TO_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_wl.yaml file must be updated with your own routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.20 ðŸš€ Python-3.11.8 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 268 layers, 68127420 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/juanc/code/rhino/scr/content/data/final_data/valid/labels.cache... 150 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        150        262      0.927      0.899      0.951      0.807\n",
      "               buffalo        150         60      0.895      0.867      0.914      0.778\n",
      "              elephant        150         83      0.863      0.892      0.952      0.757\n",
      "                 rhino        150         58      0.983      0.985      0.994      0.894\n",
      "                 zebra        150         61      0.967      0.852      0.944        0.8\n",
      "Speed: 2.6ms preprocess, 40.8ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "    \n",
    "metrics = model.val(\n",
    "    data='./content/data/final_data/data_wl.yaml',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.20 ðŸš€ Python-3.11.8 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/juanc/code/rhino/scr/content/data/final_data/test/labels... 151 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 151/151 [00:00<00:00, 894.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/juanc/code/rhino/scr/content/data/final_data/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:20<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        151        266      0.948      0.828      0.932      0.787\n",
      "               buffalo        151         44      0.984      0.727      0.911      0.802\n",
      "              elephant        151         62      0.912      0.834       0.92      0.754\n",
      "                 rhino        151         60       0.96        0.9      0.949      0.816\n",
      "                 zebra        151        100      0.935       0.85      0.947      0.775\n",
      "Speed: 33.0ms preprocess, 39.5ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "test_metrics = model.val(\n",
    "    data='./content/data/final_data/data_wl.yaml',\n",
    "    split='test'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/juanc/code/rhino/scr/../docs/yorkshire_wildlife_park_rhino_001.jpg: 448x640 2 rhinos, 261.5ms\n",
      "Speed: 5.5ms preprocess, 261.5ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Predict on a new photo\n",
    "\n",
    "photo_results = model('../docs/yorkshire_wildlife_park_rhino_001.jpg') \n",
    "\n",
    "for r in photo_results:\n",
    "    print(r.masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "for i, r in enumerate(photo_results):\n",
    "    # Plot results image\n",
    "    im_bgr = r.plot()  # BGR-order numpy array\n",
    "    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "\n",
    "    # Show results to screen (in supported environments)\n",
    "    r.show()\n",
    "\n",
    "    # Save results to disk\n",
    "    r.save(filename=f'results{i}.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
